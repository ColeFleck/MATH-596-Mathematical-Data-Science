{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from itertools import islice\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining if a Celebrity is Smiling\n",
    "\n",
    "In this homework, we will download a relatively large data set (1.5GB) of images of celebrities and determine which of them are smiling or not.  In the data set, the images have labeled attributes, one of which being if the person in the photo is smiling.  Thus we are performing a binary classification of an image, but we are doing it on a relatively small feature in the larger image.  \n",
    "\n",
    "## Getting the CelebA Data Set\n",
    "\n",
    "This could take a minute!  To enrich our data set, note that we add randomly cropped and flipped versions of the images to the training data set.  This echoes the way we built redundant dictionaries of images in Homework 9.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './' # just store everything to your local working directory\n",
    "CelebA_data_path = image_path + '/celeba'\n",
    "torch.manual_seed(1)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop([178,178]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop([178,178]),\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "get_smile = lambda attr: attr[31]\n",
    "dval = False\n",
    "if not os.path.isdir(CelebA_data_path): # if you've already downloaded and converted the MNIST images, skip\n",
    "    dval = True    \n",
    "\n",
    "# Download and convert CelebA images into tensor format. \n",
    "celeba_dataset_train = torchvision.datasets.CelebA(image_path, split='train', target_type='attr', download=dval, \n",
    "                                                   transform=transform_train, target_transform=get_smile)\n",
    "    \n",
    "celeba_dataset_valid = torchvision.datasets.CelebA(image_path, split='valid', transform=transform, \n",
    "                                                       target_type='attr', download=dval, target_transform=get_smile)\n",
    "    \n",
    "celeba_dataset_test = torchvision.datasets.CelebA(image_path, split='test', transform=transform, \n",
    "                                                       target_type='attr', download=dval, target_transform=get_smile)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see some faces from different perspectives when you run the next cell. If not, something is wrong.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "data_loader = DataLoader(celeba_dataset_train, batch_size=2)\n",
    "num_perspectives = 5\n",
    "for jj in range(num_perspectives):\n",
    "    img_batch, label_batch = next(iter(data_loader))\n",
    "\n",
    "    img = img_batch[0]\n",
    "    ax = fig.add_subplot(2,5,jj+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(img.permute(1,2,0))\n",
    "    \n",
    "    img = img_batch[1]\n",
    "    ax = fig.add_subplot(2,5,jj+6)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(img.permute(1,2,0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we decide on a batch size for running Stochastic Gradient Descent and then get our training data into the proper format for iterating over epochs with a random shuffle into new batches at every iteration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# we use a smaller version of the training and validation sets to speed up training\n",
    "celeba_dataset_train = Subset(celeba_dataset_train, torch.arange(16000))\n",
    "celeba_dataset_valid = Subset(celeba_dataset_valid, torch.arange(1000))\n",
    "\n",
    "train_dl = DataLoader(celeba_dataset_train, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(celeba_dataset_valid, batch_size, shuffle=False)\n",
    "test_dl = DataLoader(celeba_dataset_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: Building the Model\n",
    "\n",
    "Using the Convolutional_Networks_and_Pooling_Layers notebook as a model, implement the following network architecture.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "# 3 channels in, 32 channels out, kernel size=3, padding=1 2D convolutional layer\n",
    "# reLU activation function\n",
    "# max pooling layer with kernel_size = 2\n",
    "# dropout layer with p=.5 \n",
    "\n",
    "# 32 channels in, 64 channels out, kernel size=3, padding=1 2D convolutional layer\n",
    "# reLU activation function\n",
    "# max pooling layer with kernel_size = 2\n",
    "# dropout layer with p=.5 \n",
    "\n",
    "# 64 channels in, 128 channels out, kernel size=3, padding=1 2D convolutional layer\n",
    "# reLU activation function\n",
    "# max pooling layer with kernel_size = 2\n",
    "\n",
    "# 128 channels in, 256 channels out, kernel size=3, padding=1 2D convolutional layer\n",
    "# reLU activation function\n",
    "# average pooling layer with kernel_size = 8\n",
    "# flatten\n",
    "\n",
    "x = torch.ones((4, 3, 64, 64))\n",
    "dims = model(x).shape\n",
    "\n",
    "model.add_module('fc', nn.Linear(dims[1],1))\n",
    "model.add_module('sigmoid', nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: Explain what the final layer in the above model does and why we can interpret the results as probabilities.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: What is the BCELoss and why have we chosen it?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training across Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "loss_history_train = np.zeros(num_epochs)\n",
    "accuracy_history_train = np.zeros(num_epochs)\n",
    "loss_history_valid = np.zeros(num_epochs)\n",
    "accuracy_history_valid = np.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)[:, 0]\n",
    "        loss = loss_fn(pred, y_batch.float())\n",
    "        loss.backward() # perform backpropagation\n",
    "        optimizer.step() # optimize over the given batch\n",
    "        optimizer.zero_grad() # zero out the gradient for the next iteration\n",
    "        is_correct = ( (pred>=.5).float() == y_batch).float()\n",
    "        loss_history_train[epoch] += loss.item()*y_batch.size(0)\n",
    "        accuracy_history_train[epoch] += is_correct.sum()\n",
    "\n",
    "    loss_history_train[epoch] /= len(train_dl.dataset)\n",
    "    accuracy_history_train[epoch] /= len(train_dl.dataset)\n",
    "    model.eval() # Note, we need model.train() and model.eval() to manage the dropout layer correctly \n",
    "    \n",
    "    # We now look at validation data as we train to get a sense of how generalizable our model is to test data.\n",
    "\n",
    "    with torch.no_grad(): # don't optimize at this point, i.e. keep all weights fixed \n",
    "        for x_batch, y_batch in valid_dl:\n",
    "            pred = model(x_batch)[:, 0]\n",
    "            loss = loss_fn(pred, y_batch.float())\n",
    "            is_correct = ( (pred>=.5).float() == y_batch).float()\n",
    "            loss_history_valid[epoch] += loss.item()*y_batch.size(0)\n",
    "            accuracy_history_valid[epoch] += is_correct.sum()\n",
    "    loss_history_valid[epoch] /= len(valid_dl.dataset)\n",
    "    accuracy_history_valid[epoch] /= len(valid_dl.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch} accuracy: {accuracy_history_train[epoch]:.4f} \"\n",
    "          f\"val_accuracy: {accuracy_history_valid[epoch]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.arange(num_epochs)\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "ax=fig.add_subplot(1,2,1)\n",
    "ax.plot(x_arr, loss_history_train, '-o', label='Training Loss')\n",
    "ax.plot(x_arr, loss_history_valid, '-o', label='Validation Loss')\n",
    "ax.legend()\n",
    "\n",
    "ax=fig.add_subplot(1,2,2)\n",
    "ax.plot(x_arr, accuracy_history_train, '-o', label='Training Accuracy')\n",
    "ax.plot(x_arr, accuracy_history_valid, '-o', label='Validation Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: Describe why you use the `is_correct` condition that you do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_history_test = 0.\n",
    "with torch.no_grad(): # don't optimize at this point, i.e. keep all weights fixed \n",
    "    for x_batch, y_batch in test_dl:\n",
    "        pred = model(x_batch)[:, 0]\n",
    "        loss = loss_fn(pred, y_batch.float())\n",
    "        is_correct = ( (pred>=.5).float() == y_batch).float()\n",
    "        accuracy_history_test += is_correct.sum()\n",
    "    accuracy_history_test /= len(test_dl.dataset)\n",
    "    \n",
    "    print(f\"Final ccuracy: {accuracy_history_test:.4f} \")\n",
    "\n",
    "pred = model(x_batch)[:, 0] * 100. # these are the computed probabilities of whether a test image is smiling or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: Using the code above that displayed the images in the training data, and using the fact that `y_batch[jj]==1` if and only if an image is labeled as 'smiling', print out ten test images with a label on each image indicating whether they are actually smiling or not.  Along with this, also print the probability your model finds for whether they are smiling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math_596_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
